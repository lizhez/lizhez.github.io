<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-06-08T02:23:44+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Zhe Li | East China Normal University</title><subtitle>Artificial Intelligence trends and concepts made easy.</subtitle><author><name>Zhe Li (李哲)</name></author><entry><title type="html">华东师范大学数据科学与工程学院暑期夏令营实践项目总结与反思</title><link href="http://localhost:4000/huadongshifan.html" rel="alternate" type="text/html" title="华东师范大学数据科学与工程学院暑期夏令营实践项目总结与反思" /><published>2023-07-15T00:00:00+08:00</published><updated>2023-07-15T00:00:00+08:00</updated><id>http://localhost:4000/huadongshifan</id><content type="html" xml:base="http://localhost:4000/huadongshifan.html"><![CDATA[<p>在所给的四个项目中，经过仔细的考虑，选择完成【个人博客搭建】这个项目。其原因有一下三点：</p>

<ul>
  <li>首先，在比较了【关联时间序列】和【个人博客】的项目后，由于我未上手搭建过机器学习的模型，因此在14天的时间里是一个巨大的挑战。而本科期间，多项课程设计是有关网站系统的开发，选择【个人博客搭建】更加容易上手。</li>
  <li>其次，在我看来【个人博客】是一个很好的展示自己个人能力、兴趣爱好的媒介。而GitHub Pages提供的这种静态网页，可以在没有个人域名和服务器的情况下向外提供个人网站链接，是一个很好的工具。</li>
  <li>最后，我一直有过搭建个人博客来记录日常和学习的想法，但平时课程紧张，并没有来得及实现，而这次实践给了我一个合适的机会。</li>
</ul>

<p>目前为止，整个博客构建的较为仓促，后期会对其进行补充和美化，并一直记录。下面我将从5个方面介绍此项目：</p>

<h3 id="博客主题的选取">博客主题的选取</h3>

<ul>
  <li>Jekyll框架
    <ul>
      <li>Jekyll ，是由 Ruby 编写的、快速、简洁且高效的静态网站生成引擎， 使用一个模板目录作为网站布局的基础框架，并且支持 Markdown、Textile 等标记语言的解析，同时可以直接在 GitHub Pages 上使用 Jekyll来进行个人博客的搭建。</li>
      <li>本次项目，选择 Jekyll 正是由于其简易而强大的布局，可以快速上手开始项目搭建。同时 Jekyll Themes 提供了大量的页面模板，可以进行美化。</li>
    </ul>
  </li>
  <li>模板选择
    <ul>
      <li>选择 Jekyll theme: Adam Blog 2.0 为模板进行网页的开发。它提供了主页、所有文章、标签、关于我、文章详情5种页面的设计模板，界面简单整洁。</li>
    </ul>
  </li>
  <li>参考链接
    <ul>
      <li><a href="https://github.com/the-mvm/the-mvm.github.io">源主题地址：Jekyll theme: Adam Blog 2.0</a></li>
      <li><a href="https://www.bilibili.com/video/BV14x411t7ZU/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=d676acebe888563dfe01749d7eb1144f">学习教程：B站-基于 GitHub Pages 和 Jekyll 搭建个人博客的简单心得</a></li>
    </ul>
  </li>
</ul>

<h3 id="博客页面布局">博客页面布局</h3>

<ul>
  <li>PC端
    <ul>
      <li>主界面: 上方是页头，包括导航条按钮（默认关闭），博客标题，搜索按钮（可以点击以关键字搜索文章）。下方是文章列表和所有标签。最下方是页脚，包括关键的导航。
<img src="./assets/img/posts/20230715/main.png" alt="主界面" />
<img src="./assets/img/posts/20230715/search.png" alt="search" /></li>
      <li>导航: 通过点击页头左方三个横线的标志，可以展开导航栏。导航栏上方灯泡标志，控制页面的明亮或黑暗主题。
<img src="./assets/img/posts/20230715/nav.png" alt="导航" /> <img src="./assets/img/posts/20230715/nav-dark.png" alt="导航-暗" /></li>
      <li>所有文章：展示所有文章列表，竖向排列。
<img src="./assets/img/posts/20230715/all.png" alt="所有文章" /></li>
      <li>标签：根据文章标签展示文章。
<img src="./assets/img/posts/20230715/tag.png" alt="标签" /></li>
      <li>关于我：个人简单介绍。
<img src="./assets/img/posts/20230715/me.png" alt="me" /></li>
      <li>文章详情：文章详情页。中间的正文，左侧的标签，而部分页面会显示导航，以及分享的链接按钮，最下方包括其他文章，作者信息，评论。
<img src="./assets/img/posts/20230715/detail.png" alt="detail" />
<img src="./assets/img/posts/20230715/nags.png" alt="nags" />
<img src="./assets/img/posts/20230715/other.png" alt="other" />
<img src="./assets/img/posts/20230715/com.png" alt="com" /></li>
    </ul>
  </li>
  <li>移动端
  <img src="./assets/img/posts/20230715/phone.jpg" alt="phone" /></li>
</ul>

<h3 id="博客功能实现">博客功能实现</h3>

<ul>
  <li>分页
    <ul>
      <li>通过 Jekyll 中的分页插件实现主界面中文章的分页功能，这里设置六篇文章为一页。使用 ”jekyll install paginator“ 进行下载。</li>
      <li>根据当前页面是否由前一个或后一个进行自动的变化。</li>
      <li><img src="./assets/img/posts/20230715/pages.png" alt="pages" /></li>
    </ul>
  </li>
  <li>搜索
    <ul>
      <li>这里可以通过关键字，对文章标题和文章内容进行检索。</li>
    </ul>
  </li>
  <li>标签
    <ul>
      <li>除了对文章根据标题进行展示外，同时通过在文章页面的开头使用 “tags: [ 学习笔记]” 为每个文章添加标签。此时可以根据标签对文章进行搜索。这里举例以证据学习查询，可以看到</li>
      <li><img src="./assets/img/posts/20230715/e1.png" alt="e1" /></li>
      <li><img src="./assets/img/posts/20230715/e2.png" alt="e2" /></li>
    </ul>
  </li>
  <li>评论
    <ul>
      <li>使用 GitHub APPs 中的 utterances 实现评论功能</li>
      <li>
        <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">#</span> <span class="nx">Comments</span>
<span class="nx">comments</span><span class="p">:</span> <span class="nx">utteranc</span>  <span class="err">#</span><span class="p">[</span><span class="nx">disqus</span><span class="p">,</span> <span class="nx">utteranc</span><span class="p">]</span>
<span class="nx">comments_opts</span><span class="p">:</span>
<span class="nx">comments_curtain</span><span class="p">:</span> <span class="nx">yes</span> <span class="err">#</span> <span class="nx">leave</span> <span class="nx">empty</span> <span class="nx">to</span> <span class="nx">show</span> <span class="nx">the</span> <span class="nx">disqus</span> <span class="nx">embed</span> <span class="nx">directly</span>
<span class="nx">repo</span><span class="p">:</span> <span class="nx">lizhez</span><span class="o">/</span><span class="nx">lizhez</span><span class="p">.</span><span class="nx">github</span><span class="p">.</span><span class="nx">io</span> <span class="err">#</span> <span class="nx">The</span> <span class="nx">GitHub</span> <span class="nx">repo</span> <span class="nx">URL</span><span class="p">.</span>  <span class="nx">https</span><span class="p">:</span><span class="c1">//utteranc.es/</span>
<span class="nx">issue_term</span><span class="p">:</span> <span class="nx">title</span> <span class="err">#</span> <span class="nx">The</span> <span class="nx">GitHub</span> <span class="nx">issue</span> <span class="nx">label</span>
<span class="nx">theme</span><span class="p">:</span> <span class="nx">github</span><span class="o">-</span><span class="nx">light</span> <span class="err">#</span> <span class="nx">The</span> <span class="nx">GitHub</span> <span class="nx">comment</span><span class="dl">'</span><span class="s1">s there. e.g. github-dark
</span></code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h3 id="博客制作过程中遇到的问题">博客制作过程中遇到的问题</h3>

<ol>
  <li>
    <p>参考资料相对较少</p>

    <p>相较于大型 web开发 框架（如 SpringBoot）网上存在大量资源和教程不同，Jekyll由于其轻量、简单的特点，从环境配置安装到使用，网络上系统化的学习资料很少。因此主要是根据实战视频，来了解 Jekyll 框架的结构和功能，并通过实际上手，来观察具体操作会影响到页面上什么内容的改变。</p>
  </li>
  <li>
    <p>LaTeX公式书写的复杂度</p>

    <p>之前在记录学习笔记时，为了简单快速，很多都是直接截屏处理。而此尝试使用 LaTeX公式 的书写，来美化文章页面。由于时间问题，只在其中一个页面 <a href="https://lizhez.github.io/Dirichlet.html">理解狄利克雷</a> 使用。</p>
  </li>
</ol>

<h3 id="总结">总结</h3>

<p>经过此次实践过程，新学习了一项新的技术，同时完成了个人博客的搭建。这不仅仅是一项实践任务，同时也是一项可以实际使用的功能，向外提供了交流和学习的途径。</p>

<p>当前博客还有很多不足，计划在后续增加分类、播放等其他功能，继续完善。</p>]]></content><author><name>李哲</name></author><category term="学习笔记" /><summary type="html"><![CDATA[夏令营项目--个人博客，总结反思]]></summary></entry><entry><title type="html">等疫情结束就去趟海边吧</title><link href="http://localhost:4000/to-qingdao.html" rel="alternate" type="text/html" title="等疫情结束就去趟海边吧" /><published>2023-04-10T21:32:20+08:00</published><updated>2023-04-10T21:32:20+08:00</updated><id>http://localhost:4000/to-qingdao</id><content type="html" xml:base="http://localhost:4000/to-qingdao.html"><![CDATA[<p>说到海边，我想到的就是阳光、沙滩、椰子，从日出坐到日落。</p>

<p>晒晒太阳，吹吹海风，看一盛大日出和日落。</p>

<p>但其实，海边也可以是礁石，鲜花和海风。</p>

<p>青岛的海是多变的。冬天，他凌冽而广阔，静谧的海面似乎蕴藏着巨大的谜团。春日，他温柔而清凉，海鸥盘旋在海的上空，仿佛一双温柔的手抚平心中的不安与焦虑。</p>

<h3 id="看海">看海</h3>
<p>在海边看着太阳缓缓从天边升起，一层金光逐渐洒向海面，慢慢拂上我的肩膀。清晨的海边是静悄悄的，阳光驱散黑暗的同时也仿佛带走了我们的疲惫。连夜赶路的困倦瞬间消失的无影无踪，这是大海带来的震撼与惊喜。
<img src="./assets/img/posts/20230410/three.jpg" alt="看海" /></p>

<h3 id="奔跑">奔跑</h3>
<p>下午，从大学路到龙江路，向信号山公园走去。大学路的红墙黄瓦，龙江路的卡通墙绘，古风和动漫有了奇妙的结合。一路上车辆很少，我们奔跑在狭窄的马路上，是青春肆意的洒脱。
<img src="./assets/img/posts/20230410/run.jpg" alt="奔跑" /></p>]]></content><author><name>李哲</name></author><category term="旅行" /><category term="海边" /><category term="摄影" /><summary type="html"><![CDATA[我们终将告别黄昏，从此挣脱阴暗，向光里坠落]]></summary></entry><entry><title type="html">Evidential Deep Learning</title><link href="http://localhost:4000/evidential-deep-learning.html" rel="alternate" type="text/html" title="Evidential Deep Learning" /><published>2022-12-12T00:00:00+08:00</published><updated>2022-12-12T00:00:00+08:00</updated><id>http://localhost:4000/evidential-deep-learning</id><content type="html" xml:base="http://localhost:4000/evidential-deep-learning.html"><![CDATA[<h3 id="问题">问题</h3>
<ul>
  <li>由于标准方法是训练网络以使预测损失最小化，模型对其预测置信度一无所知。</li>
  <li>已有的<strong>方式：</strong>通过权重不确定性间接推断预测不确定性的贝叶斯神经网络</li>
  <li><strong>提出：</strong>使用主观逻辑理论（SL）的显式建模。在类概率上放置狄利克雷分布，将神经网络的预测视为主观意见。学习从数据中收集导致这些意见的确定性神经网络的证据的函数。</li>
  <li><strong>Softmax存在的问题：</strong>夸大预测类别的概率，结果是不可靠的不确定性估计。（预测的标签的距离除了与其他类别的比较值外，对结论没有用处）
<img src="./assets/img/posts/20221212/cite.png" alt="举例" /></li>
</ul>

<h3 id="理论说明">理论说明</h3>
<ul>
  <li>
    <p><strong>Subjective Logic (SL)主观逻辑</strong>，为每个单例提供 可信度 bk 考虑 K 个互斥单例(类标签)，并提供总体不确定性u。</p>

    <p><img src="./assets/img/posts/20221212/1.png" alt="Untitled" /></p>

    <ul>
      <li>
        <p>可信度 bk 由单例的证据 ek 计算。设 ek≥0 为第 k 个单例的证据，可信度 bk 和不确定性 u 计算为</p>

        <p><img src="./assets/img/posts/20221212/2.png" alt="Untitled" /></p>

        <p><img src="./assets/img/posts/20221212/3.png" alt="Untitled" /></p>
      </li>
      <li>
        <p>不确定性与总证据成反比</p>
        <ul>
          <li>当没有证据时，每个单例的信度为0，不确定性为1。</li>
          <li><strong>证据</strong>是从数据中收集的支持量的度量，用以支持将样本分类到某个类别。</li>
          <li><strong>可信度</strong>（主观意见），对应于 参数αk = ek + 1的狄利克雷分布</li>
          <li>bk = (αk−1)/S，从相应的狄利克雷分布的参数中得到主观意见，S =∑k αi被称为狄利克雷强度</li>
          <li>
            <p><img src="./assets/img/posts/20221212/4.png" alt="Untitled" /></p>
          </li>
          <li><img src="./assets/img/posts/20221212/5.png" alt="Untitled" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>举例
    <ul>
      <li>假设b = &lt; 0，…， 0 &gt;为10类分类问题的可信度分配。则对图像进行分类的先验分布变为均匀分布，即D(p; &lt; 1，…， 1 &gt;) 参数均为1的狄利克雷分布。简单说就是因为没有观察到的证据，所以可信度都是零。不包含任何信息，意味着完全不确定性，即u = 1。</li>
      <li>经过一些训练，让可信度变为 b = &lt; 0.8, 0，…，0 &gt;。这意味着对观点的总信任度（∑bk）是0.8，剩下的0.2是不确定性（u）。狄利克雷强度计算为 S = 10/0.2 = 50。因此，第一类得到的新证据量计算为 50 × 0.8 = 40。在这种情况下，对应狄利克雷分布D(p; &lt; 41,1，…, 1〉)。</li>
    </ul>
  </li>
  <li>对于给定一个观点，第k个单例（标签类别）的期望概率是对应的狄利克雷分布的平均值。即最终的预测概率。</li>
</ul>

<p><img src="./assets/img/posts/20221212/6.png" alt="Untitled" /></p>]]></content><author><name>李哲</name></author><category term="证据学习" /><category term="论文笔记" /><summary type="html"><![CDATA[论文《Evidential Deep Learning》的阅读笔记]]></summary></entry><entry><title type="html">理解狄利克雷分布</title><link href="http://localhost:4000/Dirichlet.html" rel="alternate" type="text/html" title="理解狄利克雷分布" /><published>2022-12-11T00:00:00+08:00</published><updated>2022-12-11T00:00:00+08:00</updated><id>http://localhost:4000/Dirichlet</id><content type="html" xml:base="http://localhost:4000/Dirichlet.html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/69606875">知乎：深入理解Beta分布</a></p>

<p>在看一篇有关证据学习的文章时，文中使用了狄利克雷分布，对此很是迷惑，在搜索大量资料后总结了有关狄利克雷的相关知识。希望可以帮助有需要者快速简单理解。本文中主要的论述来自上述链接。</p>

<h3 id="beta分布">Beta分布</h3>
<p>在了解狄利克雷分布之前，首先需要了解Beta分布，因为狄利克雷分布其本质上就是Beta分布的多元表示。因此本文主要介绍Beta分布，以引出狄利克雷分布。</p>

<p>我们都了解二项分布，其中若随机变量 X 付出参数为 n 和 q 的二项分布，则其概率密度函数为</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
p(x)=\begin{pmatrix}
n\\
x
\end{pmatrix}q^x(1-q)^{n-x}<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>如果将其看作是关于 q 的函数，即表示某件事件以概率 q 出现成为了一个事件，其本身也具有了概率。此时某种事件已经可以看作是一个已知的固定事件，即 x,n为常数，我们只是在考虑概率的概率。这时将其表述为一个分布为</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
f(q)=kq^a(1-q)^b<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>其中 a,b 是常数，则对于此时的事件所有概率出现总和应当为1。有</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
f(q)=kq^a(1-q)^b
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
\int_{0}^{1}f(q)dq=\int_{0}^{1}kq^a(1-q)^bdq=k\int_{0}^{1}q^a(1-q)^bdq=1
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
k=\frac{1}{\int_{0}^{1}q^a(1-q)^bdq}\ <br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>对于Beta分布，通常记为B(a+1,b+1)，这里 +1 我认为只是为了和Gamma函数对应起来更加简洁。</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
B(a+1,b+1)=\int_{0}^{1}q^a(1-q)^bdq, 则<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
k=B(a+1,b+1)^{-1}<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
f(q;a+1,b+1)=B(a+1,b+1)^{-1}q^a(1-q)^b<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>对其进行改造，使得α=a+1,β=b+1，当q=t时得到Beta函数；当q=x时，得到Beta分布函数</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
B(\alpha,\beta)=\int_{0}^{1}t^{\alpha-1}(1-t)^{\beta-1}dt, 则<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
f(x;\alpha,\beta)=B(\alpha,\beta)^{-1}x^{\alpha-1}(1-x)^{\beta-1}<br />
\end{split}<br />
\end{align}<br />
\)</p>

<h3 id="beta分布和gamma函数的关系">Beta分布和Gamma函数的关系</h3>
<p><img src="./assets/img/posts/20221211/beta.png" alt="beta" />
假设向长度为1的桌子上扔一个红球，会落在0到1这个范围内，设这个长度值为 x ，再向桌上扔一个白球，那么这个白球落在红球左边的概率即为 x 。 若一共扔了 n 次白球，其中每一次都是相互独立的，假设落在红球左边的白球数量为 k，那么随机变量 K 服从参数为 n 和 x 的二项分布。而对于 x 则服从 [0,1] 的均匀分布 X~U[0,1]。
对于所有的K和x有</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
P(K=k)=\int_{0}^{1}
\begin{pmatrix}
n\\
x
\end{pmatrix}x^k(1-x)^{n-k}dx=
\begin{pmatrix}
n\\
x
\end{pmatrix}\int_{0}^{1}x^k(1-x)^{n-k}dx<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>另一种丢球方式，一次性将n+1个球丢出，随机选择一个球作为红球。 则任何球被选中的概率为1/n+1。同样，红球左边有0，1，…，n个球的概率也是 1/n+1。（第一个球被选中=左边有0个球，第二个球被选中=左边有1个球，…， 第n+1个球被选中=左边有n个球） 此时有</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
P(K=k)=\int_{0}^{1}
\begin{pmatrix}
n\\
x
\end{pmatrix}x^k(1-x)^{n-k}dx \\=
\begin{pmatrix}
n\\
x
\end{pmatrix}\int_{0}^{1}x^k(1-x)^{n-k}dx=\frac{1}{n+1}\<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
\int_{0}^{1}x^k(1-x)^{n-k}dx=\frac{(n-k)!k!}{n!}\frac{1}{n+1}=\frac{k!(n-k)!}{(n+1)!}\<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>而Gamma函数的定义是</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
\Gamma(m)=\int_{0}^{+\infty}e^(-x)x^{m-1}dx=(m-1)!\<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>令 k=α-1,n-k=β-1，即n=a+b-2，可得到</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
B(\alpha,\beta)=\int_{0}^{1}t^{\alpha-1}(1-t)^{\beta-1}dt=\frac{(\alpha-1)!(\beta-1)!}{(\alpha+\beta-1)!}<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)!}<br />
\end{split}<br />
\end{align}<br />
\)</p>

<h3 id="狄利克雷分布">狄利克雷分布</h3>
<p>正如前文所说，狄利克雷分布是多元的Beta分布，有
<img src="./assets/img/posts/20221211/gamma.jpg" alt="gamma" />
其中参数α常常被用作证据学习中的证据表示。其代表此证据出现的概率，即可信度。</p>]]></content><author><name>李哲</name></author><category term="opinion" /><category term="Dirichlet" /><category term="Beta" /><category term="机器学习" /><category term="证据学习" /><summary type="html"><![CDATA[如何理解狄利克雷分布]]></summary></entry></feed>